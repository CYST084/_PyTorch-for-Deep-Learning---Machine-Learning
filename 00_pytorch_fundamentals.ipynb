{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 00. Pytorch Fundamentals\n",
    "Resources and References:\n",
    "* Github Page: https://github.com/mrdbourke/pytorch-deep-learning\n",
    "* Book version: https://www.learnpytorch.io\n",
    "* YouTube: http://www.youtube.com/watch?v=V_xro1bcAuA\n",
    "* [3blue1brown's Essence of linear algebra]()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.1+cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# import pandas as pd\n",
    "import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to Tensors\n",
    "\n",
    "Creating Tensors\n",
    "\n",
    "Pyorch tensors are created using torch.Tensor() = https://pytorch.org/docs/stable/tensors.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scalar\n",
    "\n",
    "A scalar has no (zero) dimensions.\n",
    "\n",
    "Its a single number\n",
    "\n",
    "Named with lowercase\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scalar\n",
    "\n",
    "scalar = torch.tensor(7)\n",
    "scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To get Tensor back as python int we use .item()\n",
    "scalar.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vector\n",
    "\n",
    "A number with magnitude(size) and direction (eg. wind speed with direction) but can have many other numbers\n",
    "\n",
    "It has 1 dimension\n",
    "\n",
    "Dimensions -> No. of pairs of closing square brackets\n",
    "\n",
    "Shape\n",
    "\n",
    "Named with lowercase\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7, 7])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vector\n",
    "vector = torch.tensor([7, 7])\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MATRIX\n",
    "\n",
    "A 2-dimensional array of numbers\n",
    "\n",
    "Named with Uppercase\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 7,  8],\n",
       "        [ 9, 10]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MATRIX\n",
    "MATRIX = torch.tensor([[7, 8], [9, 10]])\n",
    "MATRIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MATRIX.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MATRIX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value at Index on zero'th axis: \n",
      " tensor([7, 8])\n",
      "Value at index on first dimension: \n",
      " tensor([ 9, 10])\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    f\"Value at Index on zero'th axis: \\n {MATRIX[0]}\\nValue at index on first dimension: \\n {MATRIX[1]}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MATRIX.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor\n",
    "\n",
    "An n-dimensional array of numbers.\n",
    "can be any no.\n",
    "\n",
    "Named with Uppercase\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 2, 3],\n",
       "         [3, 6, 9],\n",
       "         [2, 4, 5]]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TENSOR\n",
    "TENSOR = torch.tensor([[[1, 2, 3], [3, 6, 9], [2, 4, 5]]])\n",
    "TENSOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 3])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the tensor TENSOR of shape -> torch.size([1, 3, 3])\n",
    "\n",
    "This means there's 1 dimension of 3 by 3\n",
    "\n",
    "dim=0 the outside bracket lines up with (1)\n",
    "\n",
    "dim=1 the middle bracket lines up with (3)\n",
    "\n",
    "dim=2 the inner bracket lines up with (3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [3, 6, 9],\n",
       "        [2, 4, 5]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dim = 0\n",
    "TENSOR[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Random Tensors in Pytorch\n",
    "\n",
    "### Why random tensors?\n",
    "\n",
    "Neural nets learns by starting with tensors full of random numbers then adjust those random numbers to better represent the data\n",
    "\n",
    "Torch random tensors - https://pytorch.org/docs/stable/generated/torch.rand.html\n",
    "(torch.rand)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6540, 0.5621, 0.4263, 0.9757],\n",
       "        [0.0549, 0.5366, 0.9981, 0.0759],\n",
       "        [0.1060, 0.5681, 0.6028, 0.8843]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a random tensor of size (3, 4)\n",
    "random_tensor = torch.rand(3, 4)\n",
    "random_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# no. of dimensions of random_tensor\n",
    "random_tensor.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: torch.Size([224, 224, 3])\n",
      "ndim: 3\n"
     ]
    }
   ],
   "source": [
    "# create a random tensor with similar shape to an image tensor\n",
    "random_image_size_tensor = torch.rand(\n",
    "    size=(224, 224, 3)\n",
    ")  # height, width, color channels(R, G, B)\n",
    "\n",
    "print(f\"Shape: {random_image_size_tensor.shape}\\nndim: {random_image_size_tensor.ndim}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Tensors with Zeros and Ones in PyTorch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a tensor of all zeros\n",
    "\n",
    "zeros = torch.zeros(size=(3, 4))\n",
    "zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zeros * random_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a tensor of all ones\n",
    "\n",
    "ones = torch.ones(size=(3, 4))\n",
    "ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data type\n",
    "ones.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### -> Creating tensors in a range and tensors-like\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a range using torch.arange()\n",
    "\n",
    "one_to_nine = torch.arange(0, 10)\n",
    "one_to_nine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_to_ten = torch.arange(1, 11)\n",
    "one_to_ten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  0,  77, 154, 231, 308, 385, 462, 539, 616, 693, 770, 847, 924])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero_to_thousand = torch.arange(start=0, end=1000, step=77)\n",
    "zero_to_thousand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating tensors like\n",
    "ten_zeros = torch.zeros_like(input=one_to_ten)\n",
    "ten_zeros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### -> Dealing with Tensor datatypes\n",
    "\n",
    "**Note:** Tensor datatypes is one of the 3 big errors you'll run into with PyTorch & deep learning:\n",
    "\n",
    "1. Tensors not right datatype\n",
    "2. Tensors not right shape\n",
    "3. Tensors not on the right device\n",
    "\n",
    "- Default datatype is `torch.float32` (1 precision)\n",
    "- Default device is `cpu`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3., 6., 9.])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Float 32 tensor\n",
    "float_32_tensor = torch.tensor(\n",
    "    [3.0, 6.0, 9.0], dtype=None, device=None, requires_grad=False\n",
    ")\n",
    "float_32_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_32_tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3., 6., 9.], dtype=torch.float16)\n",
      "torch.float16\n"
     ]
    }
   ],
   "source": [
    "# Float 16 tensor\n",
    "float_16_tensor = torch.tensor(\n",
    "    [3.0, 6.0, 9.0], dtype=torch.float16, device=None, requires_grad=False\n",
    ")\n",
    "print(float_16_tensor)\n",
    "print(float_16_tensor.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3., 6., 9.], dtype=torch.float16)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_16_tensor2 = float_32_tensor.type(torch.float16)\n",
    "float_16_tensor2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Some tensor operations with different datatypes, will work some times but most of the time result in errors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 9., 36., 81.])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_16_tensor * float_32_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 6, 9], dtype=torch.int32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int_32_tensor = torch.tensor([3, 6, 9], dtype=torch.int32)\n",
    "int_32_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 9., 36., 81.], dtype=torch.float16)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int_32_tensor * float_16_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### -> Getting tensor attributes (information about tensors)\n",
    "\n",
    "1. Tensor's datatype - `tensor.dtype`\n",
    "2. Tensor's shape - `tensor.shape`\n",
    "3. Tensor's device - `tensor.device`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6970, 0.4412, 0.6589, 0.7323],\n",
       "        [0.0986, 0.5292, 0.9261, 0.7214],\n",
       "        [0.5724, 0.0330, 0.2224, 0.7828]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor\n",
    "some_tensor = torch.rand(3, 4)\n",
    "some_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6970, 0.4412, 0.6589, 0.7323],\n",
      "        [0.0986, 0.5292, 0.9261, 0.7214],\n",
      "        [0.5724, 0.0330, 0.2224, 0.7828]])\n",
      "Datatype of tensor: torch.float32\n",
      "Shape of tensor: torch.Size([3, 4])\n",
      "Device tensor is on: cpu\n"
     ]
    }
   ],
   "source": [
    "# Find out details about some_tensor\n",
    "print(some_tensor)\n",
    "print(f\"Datatype of tensor: {some_tensor.dtype}\")\n",
    "print(f\"Shape of tensor: {some_tensor.shape}\")\n",
    "print(f\"Device tensor is on: {some_tensor.device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### -> Manipulating Tensors (Tensor Operations)\n",
    "\n",
    "Tensor operations:\n",
    "\n",
    "- Addition\n",
    "- Subtraction\n",
    "- Multiplication (element-wise)\n",
    "- Duvision\n",
    "- Matrix multiplicatin\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original tensor:\n",
      "tensor([1, 2, 3])\n",
      "Resulting tensor after adding 10:\n",
      "tensor([11, 12, 13])\n"
     ]
    }
   ],
   "source": [
    "# Create a tensor and add 10 to it\n",
    "\n",
    "tensor = torch.tensor([1, 2, 3])\n",
    "\n",
    "tensor_plus_10 = tensor + 10\n",
    "print(f\"Original tensor:\\n{tensor}\")\n",
    "print(f\"Resulting tensor after adding 10:\\n{tensor_plus_10}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original tensor:\n",
      "tensor([1, 2, 3])\n",
      "Resulting tensor after multiplying by 10:\n",
      "tensor([10, 20, 30])\n"
     ]
    }
   ],
   "source": [
    "# Multiply tensor by 10\n",
    "\n",
    "tensor_times_10 = tensor * 10\n",
    "print(f\"Original tensor:\\n{tensor}\")\n",
    "print(f\"Resulting tensor after multiplying by 10:\\n{tensor_times_10}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original tensor:\n",
      "tensor([1, 2, 3])\n",
      "Resulting tensor after subtructing 10:\n",
      "tensor([-9, -8, -7])\n"
     ]
    }
   ],
   "source": [
    "# Subtract tensor by 10\n",
    "\n",
    "tensor_minus_10 = tensor - 10\n",
    "print(f\"Original tensor:\\n{tensor}\")\n",
    "print(f\"Resulting tensor after subtructing 10:\\n{tensor_minus_10}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original tensor:\n",
      "tensor([1, 2, 3])\n",
      "Resulting tensor after applying PyTorch mul by 10:\n",
      "tensor([10, 20, 30])\n"
     ]
    }
   ],
   "source": [
    "# Using PyTorch built-in functions\n",
    "tensor_torch_mul_10 = torch.mul(tensor, 10)\n",
    "print(f\"Original tensor:\\n{tensor}\")\n",
    "print(f\"Resulting tensor after applying PyTorch mul by 10:\\n{tensor_torch_mul_10}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### -> Matrix mutiplication (part 1)\n",
    "\n",
    "Two main ways of performing multiplication:\n",
    "\n",
    "1. Element-wise\n",
    "2. Matrix multiplication (dot product)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3]) * tensor([1, 2, 3])\n",
      "Equals: tensor([1, 4, 9])\n"
     ]
    }
   ],
   "source": [
    "# Element wise multiplication\n",
    "print(tensor, \"*\", tensor)\n",
    "print(f\"Equals: {tensor * tensor}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original tensor matmul:\n",
      "tensor([1, 2, 3]) * tensor([1, 2, 3])\n",
      "Resulting tensor matrix multiplication:\n",
      "14\n"
     ]
    }
   ],
   "source": [
    "# Matrix multiplication\n",
    "# %%time\n",
    "tensor_matmul = torch.matmul(tensor, tensor)\n",
    "print(f\"Original tensor matmul:\\n{tensor} * {tensor}\")\n",
    "print(f\"Resulting tensor matrix multiplication:\\n{tensor_matmul}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Matrix multiplication by hand\n",
    "1 * 1 + 2 * 2 + 3 * 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(14)\n"
     ]
    }
   ],
   "source": [
    "# Matrix multiplication by hand, for loop\n",
    "# %%time\n",
    "value = 0\n",
    "for i in range(len(tensor)):\n",
    "    value += tensor[i] * tensor[i]\n",
    "print(value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### -> Matrix multiplication (part 2: the two main rules of matrix multplication)\n",
    "\n",
    "There are two main rules that performing matrix multiplication needs to satisfy:\n",
    "\n",
    "1. The **inner dimensions** must match:\n",
    "\n",
    "- `(3, 2) @ (3, 2)` won't work\n",
    "- `(2, 3) @ (3, 2)` will work\n",
    "- `(3, 2) @ (2, 3)` will\n",
    "\n",
    "2. The resulting matrix has the shape of ht **outer dimensions**:\n",
    "\n",
    "- `(2, 3) @ (3, 2)` -> `(2, 2)`\n",
    "- `(3, 2) @ (2, 3)` -> `(3, 3)`\n",
    "\n",
    "Some important links:\n",
    "\n",
    "- https://mathisfun.com\n",
    "- https://matrixmultiplication.xyz\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### -> Matrix multiplication (part 3: dealing with tensor shape errors)\n",
    "\n",
    "- To fix tensor shape issues, we can manipulate the shape of one of our tensors using a **transpose**.\n",
    "- A **transpose** switches the axes or dimensions of a given tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 2]), torch.Size([3, 2]))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shapes for matrix mul\n",
    "tensor_A = torch.tensor([[1, 2], [3, 4], [5, 6]])\n",
    "\n",
    "tensor_B = torch.tensor([[7, 10], [8, 11], [9, 12]])\n",
    "\n",
    "tensor_A.shape, tensor_B.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 7,  8,  9],\n",
       "         [10, 11, 12]]),\n",
       " torch.Size([2, 3]))"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_B.T, tensor_B.T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shapes: tensor_A = torch.Size([3, 2]), tensor_B = torch.Size([3, 2])\n",
      "New shapes: tensor_A = torch.Size([3, 2]) (same shape as above), tensor_B.T = torch.Size([3, 2])\n",
      "Multiplying: torch.Size([3, 2]) @ torch.Size([2, 3]) <- inner dims must match\n",
      "Output:\n",
      "\n",
      "tensor([[ 27,  30,  33],\n",
      "        [ 61,  68,  75],\n",
      "        [ 95, 106, 117]])\n",
      "\n",
      "Output shape: torch.Size([3, 3])\n"
     ]
    }
   ],
   "source": [
    "# We transpose tensor_B for the matrix mul to work (for inner dim to be same)\n",
    "print(f\"Original shapes: tensor_A = {tensor_A.shape}, tensor_B = {tensor_B.shape}\")\n",
    "print(\n",
    "    f\"New shapes: tensor_A = {tensor_A.shape} (same shape as above), tensor_B.T = {tensor_B.shape}\"\n",
    ")\n",
    "print(f\"Multiplying: {tensor_A.shape} @ {tensor_B.T.shape} <- inner dims must match\")\n",
    "print(\"Output:\\n\")\n",
    "\n",
    "output = torch.mm(tensor_A, tensor_B.T)  # torch.mm == torch.matmul == '@' operator.\n",
    "print(output)\n",
    "print(f\"\\nOutput shape: {output.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### -> Finding the min, max, mean and sum of tensors (Tensor Aggregation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0, 10, 20, 30, 40, 50, 60, 70, 80, 90])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a tensor\n",
    "tensor_x = torch.arange(start=0, end=100, step=10)\n",
    "tensor_x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0), tensor(0))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finding the min\n",
    "torch.min(tensor_x), tensor_x.min()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(90), tensor(90))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finding the max\n",
    "torch.max(tensor_x), tensor_x.max()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_x.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(45.), tensor(45.))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mean -> does not work with Long(int64) dtype, can only work with either float32 or complex dtypes\n",
    "torch.mean(tensor_x.type(torch.float32)), tensor_x.type(torch.float32).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(450), tensor(450))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sum\n",
    "torch.sum(tensor_x), tensor_x.sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### -> Finding the positional min and max of tensors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0, 10, 20, 30, 40, 50, 60, 70, 80, 90])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finding the position in tensor that has the minimum value with argmin() -> returns index position of target tensor value where the minimum value occurs\n",
    "tensor_x.argmin()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finding the position in tensor that has the maximum value with argmax()\n",
    "tensor_x.argmax()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(90)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_x[9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### -> Reshaping, viewing, stacking, squeezing, unsqueezing and permuting tensors\n",
    "\n",
    "- **Reshaping** - reshapes an input tensor to a defined shape\n",
    "  - In _reshape_ the dimensions have to be _compatible with the original dimensions_.\n",
    "- **View** - Return a view of an input tensor of certain shape but keep the same memory as the original tensor (shows a tensor from a different perspective/shape)\n",
    "- **Stacking** - combine multiple tensors on top of each other (vstack) or side by side (hstack)\n",
    "  - Concatenates a sequence of tensors (of same size) along a new dimension\n",
    "  - `torch.stack(tensors, dim=0, out=None) -> Tensor`, where _tensors_ is the sequence of tensors to concatenate, _dim(int)_ is what dimension to combine them on, and has btw 0 and the no. of dimensions of concatenated tensors. _out(Tensor, optional)_ is the output tensor.\n",
    "  - There is also `torch.vstack` and `torch.hstack`.\n",
    "- **Squeeze** - remove all `1` dimensions from a tensor.\n",
    "- **Unsqueeze** - add a `1` dimension to a target tensor.\n",
    "- **Permute** - Return a _view_ of the input with dimensions permuted _(swapped)_ in a certain way.\n",
    "\n",
    "* The goal is to manipulate tensors in some way to change their shape or dimensions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 2., 3., 4., 5., 6., 7., 8., 9.]), torch.Size([9]))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a tensor\n",
    "tensor_y = torch.arange(1.0, 10.0)\n",
    "tensor_y, tensor_y.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 2., 3., 4., 5., 6., 7., 8., 9.]]), torch.Size([1, 9]))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add an extra dimension\n",
    "tensor_y_reshaped = tensor_y.reshape(1, 9)\n",
    "tensor_y_reshaped, tensor_y_reshaped.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1.],\n",
       "         [2.],\n",
       "         [3.],\n",
       "         [4.],\n",
       "         [5.],\n",
       "         [6.],\n",
       "         [7.],\n",
       "         [8.],\n",
       "         [9.]]),\n",
       " torch.Size([9, 1]))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_y1_reshaped = tensor_y.reshape(9, 1)\n",
    "tensor_y1_reshaped, tensor_y1_reshaped.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 2., 3., 4., 5., 6., 7., 8., 9.]), torch.Size([9]))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_y, tensor_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1.],\n",
       "         [2.],\n",
       "         [3.],\n",
       "         [4.],\n",
       "         [5.],\n",
       "         [6.],\n",
       "         [7.],\n",
       "         [8.],\n",
       "         [9.]]),\n",
       " torch.Size([9, 1]))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change the view\n",
    "z1 = tensor_y.view(9, 1)\n",
    "z1, z1.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 2., 3., 4., 5., 6., 7., 8., 9.]]), torch.Size([1, 9]))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change the view\n",
    "z = tensor_y.view(1, 9)\n",
    "z, z.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[5., 2., 3., 4., 5., 6., 7., 8., 9.]]),\n",
       " tensor([5., 2., 3., 4., 5., 6., 7., 8., 9.]))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Changing z changes tensor_y (because a view of a tensor shares the same memory as the original input)\n",
    "z[:, 0] = 5\n",
    "z, tensor_y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[5., 2., 3., 4., 5., 6., 7., 8., 9.]]), torch.Size([1, 9]))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z, z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[5., 2., 3., 4., 5., 6., 7., 8., 9.]],\n",
       "\n",
       "        [[5., 2., 3., 4., 5., 6., 7., 8., 9.]],\n",
       "\n",
       "        [[5., 2., 3., 4., 5., 6., 7., 8., 9.]],\n",
       "\n",
       "        [[5., 2., 3., 4., 5., 6., 7., 8., 9.]]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stack tensors on top of each other\n",
    "y_stacked = torch.stack([z, z, z, z], dim=0)\n",
    "y_stacked\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[5., 2., 3., 4., 5., 6., 7., 8., 9.],\n",
       "         [5., 2., 3., 4., 5., 6., 7., 8., 9.],\n",
       "         [5., 2., 3., 4., 5., 6., 7., 8., 9.],\n",
       "         [5., 2., 3., 4., 5., 6., 7., 8., 9.]]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stacking, on dim 1\n",
    "y1_stacked = torch.stack([z, z, z, z], dim=1)\n",
    "y1_stacked\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### -> Squeezing, unsqueezing and permuting tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial tensor z: tensor([[5., 2., 3., 4., 5., 6., 7., 8., 9.]])\n",
      "Shape of initial tensor z: torch.Size([1, 9])\n",
      "\n",
      "New tensor: tensor([5., 2., 3., 4., 5., 6., 7., 8., 9.])\n",
      "Shape of new (squeezed) tensor: torch.Size([9])\n"
     ]
    }
   ],
   "source": [
    "# torch.squeeze() -> removes all single dimensions from a target tensor\n",
    "print(f\"Initial tensor z: {z}\")\n",
    "print(f\"Shape of initial tensor z: {z.shape}\")\n",
    "\n",
    "# Squeeze tensor z\n",
    "z_squeezed = z.squeeze()\n",
    "print(f\"\\nNew tensor: {z_squeezed}\")\n",
    "print(f\"Shape of new (squeezed) tensor: {z_squeezed.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous target (z_squeezed) tensor: tensor([5., 2., 3., 4., 5., 6., 7., 8., 9.]),\n",
      "Shape: torch.Size([9])\n",
      "\n",
      "New (unsqueezed) tensor: tensor([[5., 2., 3., 4., 5., 6., 7., 8., 9.]]), \n",
      "shape: torch.Size([1, 9])\n"
     ]
    }
   ],
   "source": [
    "# torch.unsqueeze() - adds a single dimension to a target tensor at a specific dim\n",
    "print(f\"Previous target (z_squeezed) tensor: {z_squeezed},\\nShape: {z_squeezed.shape}\")\n",
    "\n",
    "# Add extra dimension with unsqueeze\n",
    "z_unsqueezed = z_squeezed.unsqueeze(dim=0)\n",
    "print(f\"\\nNew (unsqueezed) tensor: {z_unsqueezed}, \\nshape: {z_unsqueezed.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous shape: torch.Size([224, 224, 3]), \n",
      "(Heiht, Width, RGB color channels)\n",
      "\n",
      "New (permuted shape): torch.Size([3, 224, 224]), \n",
      "(RGB color chanels, Height, Width)\n"
     ]
    }
   ],
   "source": [
    "# torch.permute - rearranges the dimensons of a target tensor in a specified order (a view)\n",
    "x_original = torch.rand(size=(224, 224, 3)) # h, w, c\n",
    "\n",
    "# Permute the original tensor to rearrange the axis/dim order\n",
    "x_permuted = x_original.permute(2, 0, 1) # shifts (changes view) into shape c, h, w\n",
    "\n",
    "print(f\"Previous shape: {x_original.shape}, \\n(Heiht, Width, RGB color channels)\")\n",
    "print(f\"\\nNew (permuted shape): {x_permuted.shape}, \\n(RGB color chanels, Height, Width)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### -> Selecting data from tensors (indexing)\n",
    "Indexing with pyTorch is similar to indexing with NumPy\n",
    "\n",
    "- You can also use `:` to select **all** of a target dimension\n",
    "- **Slicing operations** can also be applied to tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[1, 2, 3],\n",
       "          [4, 5, 6],\n",
       "          [7, 8, 9]]]),\n",
       " torch.Size([1, 3, 3]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creatig a tensor\n",
    "x = torch.arange(start=1, end=10).reshape(1, 3, 3)\n",
    "x, x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6],\n",
       "        [7, 8, 9]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Indexing our new tensor\n",
    "x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Index on the midde bracket (dim=1)\n",
    "x[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4, 5, 6])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7, 8, 9])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0][0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0][2][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You can also use \":\" to select \"all\" of a target dimension\n",
    "x[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 5, 8]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get all values of 0th and 1st dimension but only index 1 of 2nd dimension (every middle[1] element of the innermost[:, :] bracket)\n",
    "x[:, :, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get all values of the 0 dimension but only the 1 index value of the 1st and 2nd diminsion\n",
    "x[:, 1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5, 8]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get all values of 0th dim, but index 1 elements[2nd dim] of 1st dimension  (in middle bracket, start from dim 1 to the rest/all following)\n",
    "x[:, 1:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get index 0 of 0th and 1st dimension and all values of 2nd dimension\n",
    "x[0, 0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 2, 3],\n",
       "         [4, 5, 6],\n",
       "         [7, 8, 9]]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Index on x to return 9\n",
    "x[0, 2, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3, 6, 9]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Index on x to return 3, 6, 9\n",
    "x[:, :, 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### -> PyTorch and NumPy\n",
    "NumPy is a popular scientific Python numerical computing library. PyTorch has functionality to interact with it\n",
    "\n",
    "* Convert data from NumPy arrays to PyTorch tensor -> `torch.from_numpy(ndarray)`.\n",
    "* From PyTorch tensor to NumPy array -> `torch.Tensor.numpy()`\n",
    "\n",
    "- NumPy default datatype if `float64`.\n",
    "- PyTorch default datatype is `torch.float32`.\n",
    "\n",
    "* **Warning**:\n",
    "    - When converting from NumPy to PyTorch, PyTorch reflects NumPy's default datatype of  `float64` unless specified otherwise.\n",
    "    - Same goes for PyTorch to Numpy, PyTorch tensor default datatype of `torch.float32` is reflected onto the numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1., 2., 3., 4., 5., 6., 7.]),\n",
       " tensor([1., 2., 3., 4., 5., 6., 7.], dtype=torch.float64))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NumPy array to tensor\n",
    "array = np.arange(1.0, 8.0)\n",
    "tensor = torch.from_numpy(array)\n",
    "array, tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumPy array's datatype: float64\n"
     ]
    }
   ],
   "source": [
    "print(f\"NumPy array's datatype: {array.dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2., 3., 4., 5., 6., 7., 8.]),\n",
       " tensor([1., 2., 3., 4., 5., 6., 7.], dtype=torch.float64))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# change the value of array, what will this do to `tensor`?\n",
    "array = array + 1\n",
    "array, tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 1., 1., 1., 1., 1., 1.]),\n",
       " torch.float32,\n",
       " array([1., 1., 1., 1., 1., 1., 1.], dtype=float32),\n",
       " dtype('float32'))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tensor to NumPy array\n",
    "pytorch_tensor = torch.ones(7)\n",
    "numpy_array = pytorch_tensor.numpy()\n",
    "\n",
    "pytorch_tensor, pytorch_tensor.dtype, numpy_array, numpy_array.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([2., 2., 2., 2., 2., 2., 2.]),\n",
       " array([1., 1., 1., 1., 1., 1., 1.], dtype=float32))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change the tensor, what happens to `numpy_array`?\n",
    "pytorch_tensor = pytorch_tensor + 1\n",
    "pytorch_tensor, numpy_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### -> PyTorch reproducibility (taking the random out of random)\n",
    "\n",
    "To reduce the randomness in neural networks, PyTorch comes with the concept of a **random seed**\n",
    "\n",
    "Esentially what the random seed does is \"flavour\" the randomness.\n",
    "\n",
    "Extra resources for reproducibility:\n",
    "* https://pytorch.org/docs/stable/notes/randomness.html\n",
    "* https://en.wikipedia.org/wiki/Random_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3666, 0.2320, 0.9830, 0.8959],\n",
      "        [0.7942, 0.1805, 0.1571, 0.1199],\n",
      "        [0.4936, 0.3117, 0.1440, 0.4212]])\n",
      "tensor([[0.2494, 0.8921, 0.2358, 0.8228],\n",
      "        [0.3204, 0.1929, 0.5590, 0.7827],\n",
      "        [0.6194, 0.0808, 0.2565, 0.6006]])\n",
      "tensor([[False, False, False, False],\n",
      "        [False, False, False, False],\n",
      "        [False, False, False, False]])\n"
     ]
    }
   ],
   "source": [
    "# Create two random tensors\n",
    "random_tensor_A = torch.rand(3, 4)\n",
    "random_tensor_B = torch.rand(3, 4)\n",
    "\n",
    "print(random_tensor_A)\n",
    "print(random_tensor_B)\n",
    "print(random_tensor_A == random_tensor_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n",
      "        [0.3904, 0.6009, 0.2566, 0.7936],\n",
      "        [0.9408, 0.1332, 0.9346, 0.5936]])\n",
      "tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n",
      "        [0.3904, 0.6009, 0.2566, 0.7936],\n",
      "        [0.9408, 0.1332, 0.9346, 0.5936]])\n",
      "tensor([[True, True, True, True],\n",
      "        [True, True, True, True],\n",
      "        [True, True, True, True]])\n"
     ]
    }
   ],
   "source": [
    "# Set the random seed\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "# torch.manual_seed(RANDOM_SEED) only works for one block of code, so it has to be repeated each time torch.rand() is called.\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "random_tensor_C = torch.rand(3, 4)\n",
    "\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "random_tensor_D = torch.rand(3, 4)\n",
    "\n",
    "print(random_tensor_C)\n",
    "print(random_tensor_D)\n",
    "print(random_tensor_C == random_tensor_D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### -> Running tensors and PyTorch objects on GPUs (and making faster computations)\n",
    "\n",
    "GPUs = faster computation on numbers thanks to CUDA + PyTorch working behind the scenes to make everything good(optimized to run fast)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Getting a GPU\n",
    "1. Easiest - Use Google Colab for a free GPU (options to upgrade as well)\n",
    "2. Use Kaggle - Kaggle Notebooks\n",
    "3. Use your own GPU - takes a little bit of setup and requires purchasing one.\n",
    "    - There's a lots of options..., see this post for what option to get: https://timdettmers.com/2020/09/03/which-gpu-for-deep-learning/\n",
    "4. Use cloud computing - GCP, AWS, Azure (and alot of other providers now with the AI boom). These services allow you to rent compute.\n",
    "\n",
    "\n",
    "For option 3 and 4, PyTorch + GPU drivers (CUDA) takes a little bit of setting up, to do this, refer to PyTorch documentation: https://pytorch.org/get-started/locally/\n",
    "\n",
    "For option 1 (Google Colab), change runtime to GPU, to be allocated a GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To check the allocated GPU\n",
    "# nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Check for GPU access with PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. Check for GPU access with PyTorch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For PyTorch since its capable of running compute on the GPU or CPU, it's best practice to setup device agnostic code: https://pytorch.org/docs/stable/notes/cuda.html#best-practices\n",
    "\n",
    "E.g. run on GPU if available else CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup device agnostic code\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count the number of devices (Nvidia GPUs)\n",
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### -> Setting up device agnostic code and putting tensors on and of GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "continuation...\n",
    "#### -> Putting tensors (and models) on the CPU\n",
    "\n",
    "We'll want our tensors/model on the GPU since computations are faster there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3]) cpu\n"
     ]
    }
   ],
   "source": [
    "# Create a tensor(default on the CPU)\n",
    "tensor_cpu = torch.tensor([1, 2, 3])\n",
    "\n",
    "print(tensor_cpu, tensor_cpu.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Move tensor to GPU (if available)\n",
    "tensor_on_gpu = tensor_cpu.to(device)\n",
    "tensor_on_gpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### -> Moving tensors back to the CPU\n",
    "\n",
    "- (on the device issues): **Converting tensors to numpy with `tensor.numpy()`** doesn't work with the GPU, **NumPy only works with CPU**. \n",
    "- Instead we use `tensor.cpu()` which will bring our target tensor back to CPU, and then we should be able to use it with NumPy.\n",
    "- For Instance if we run `tensor_on_gpu.numpy`, we'll get a type error. (*Only if its on GPU*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If tensor is on GPU, can't ransform it to NumPy, error if device = GPU\n",
    "# tensor_on_gpu.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3], dtype=int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To fix the GPU tensor with NumPy issue, we can first set it to the CPU\n",
    "tensor_back_on_cpu = tensor_on_gpu.cpu().numpy()\n",
    "tensor_back_on_cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_on_gpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 32. PyTorch Fundmentals exercises and extra-curriculum\n",
    "\n",
    "visit https://www.learnpytorch.io/00_pytorch_fundamentals/#extra-curriculum\n",
    "\n",
    "Github Page: https://github.com/mrdbourke/pytorch-deep-learning/blob/main/extras/exercises/00_pytorch_fundamentals_exercises.ipynb\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
